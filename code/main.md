# The Main Loop

## Implementation Details
The code was based on exercises found in "Hands-On Large Language Models", by Jay Alammar and Maarten Grootendorst.
Much of the code was written with the assistance of GPT-4o

```
Training Data          = Rotten Tomatoes dataset (from datasets package)
Target Labels          = {0,1}
Size of training set   = 8530
Size of testing set    = 1066
Size of validation set = 1066
```
Example input and output:
```
Input:  the rock is destined to be the 21st century's new " conan " and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .

Output:  1
```

